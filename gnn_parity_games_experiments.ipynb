{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN for Parity Games Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Training Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**07 July 2022**\n",
    "\n",
    "- Num games: 3000\n",
    "- Graph size (N) range: [10,200]\n",
    "- Relative outdegree $(\\frac{d_i}{N})$ range: [0.01,0.5]\n",
    "- Priority range: [0,N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = 3000\n",
    "min_n = 10\n",
    "max_n = 200\n",
    "min_rod = 0.01\n",
    "max_rod = 0.5\n",
    "\n",
    "games_dir = 'games'\n",
    "solutions_dir = 'solutions'\n",
    "pgsolver_base = 'pgsolver' # Path to compiled base dir of https://github.com/tcsprojects/pgsolver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import game_generator as gg\n",
    "\n",
    "#gg.create_games_and_solutions(num_graphs, min_n, max_n, min_rod, max_rod, games_dir, solutions_dir, pgsolver_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from parity_game_dataset import ParityGameDataset\n",
    "import math\n",
    "\n",
    "data = ParityGameDataset('pg_data_20220708', 'games', 'solutions')\n",
    "\n",
    "# Use first 70% of the data for training\n",
    "split_index = math.floor(0.7 * len(data))\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Parameters**\n",
    "\n",
    "- optimizer: Adam\n",
    "- Learning rate: 0.001\n",
    "- Loss: Cross Entropy\n",
    "- Epochs: 1-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "- Iterations: 10\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import parity_game_network as pn\n",
    "#from parity_game_network import ParityGameNetwork\n",
    "reload(pn)\n",
    "model = pn.ParityGameNetwork(256, 256, 10)\n",
    "#model = pn.ParityGameNetwork(128, 128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParityGameNetwork(\n",
       "  (core): GAT(3, 256, num_layers=10)\n",
       "  (node_classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softmax(dim=1)\n",
       "  )\n",
       "  (edge_classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexdweinert\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ce9aaa7d4444eaa13b85f91d0bd78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03333751360575358, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wein_al/development/gnn_pr_solver/wandb/run-20220927_153114-2qhd5dx1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alexdweinert/gnn_parity_game_solver/runs/2qhd5dx1\" target=\"_blank\">chocolate-snow-2</a></strong> to <a href=\"https://wandb.ai/alexdweinert/gnn_parity_game_solver\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project='gnn_parity_game_solver')\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.001\n",
    "\n",
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc Nodes: 0.9661, Test Acc Nodes: 0.9618, Train Acc Edges: 0.9124, Test Acc Edges: 0.9106\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion_nodes = torch.nn.CrossEntropyLoss()\n",
    "criterion_edges = torch.nn.CrossEntropyLoss(weight=torch.tensor([0.1,0.9]))\n",
    "\n",
    "def train():\n",
    "    running_loss = 0.\n",
    "    i = 0\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        i += 1\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        out_nodes, out_edges = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "        \n",
    "        # Most edges do not belong to a winning strategy and thus the data is extemely imbalanced. The model will probably learn that predicting always \"non-winning\" for each edge \n",
    "        # yields reasonable performance. To avoid this, approximately as many non-winning strategy edges are sampled as there are winning edges.\n",
    "        #edge_selection = (torch.rand(data.y_edges.shape[0]) > 0.7) | (data.y_edges == 1)\n",
    "        loss = criterion_nodes(out_nodes, data.y_nodes) + criterion_edges(out_edges, data.y_edges) # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:\n",
    "            last_loss = running_loss / 50 # loss per batch\n",
    "            wandb.log({'loss': last_loss, 'variance': torch.var(out_nodes[:,1])})\n",
    "            running_loss = 0.\n",
    "            \n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct_nodes = 0\n",
    "     correct_edges = 0\n",
    "\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out_nodes, out_edges = model(data.x, data.edge_index)  \n",
    "        pred_nodes = out_nodes.argmax(dim=1)  # Use the class with highest probability.\n",
    "        pred_edges = out_edges.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct_nodes += (pred_nodes == data.y_nodes).sum() / len(pred_nodes)  # Check against ground-truth labels.\n",
    "        correct_edges += (pred_edges == data.y_edges).sum() / len(pred_edges)\n",
    "     return (correct_nodes / len(loader), correct_edges / len(loader))  # Derive ratio of correct predictions.\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train()\n",
    "    train_acc_nodes, train_acc_edges = test(train_loader)\n",
    "    test_acc_nodes, test_acc_edges = test(test_loader)\n",
    "    wandb.log({'Epoch': epoch, 'Acc_Acc_Nodes': train_acc_nodes, 'Test_Acc_Nodes': test_acc_nodes, 'Train_Acc_Edges': train_acc_edges, 'Test_Acc_Edges': test_acc_edges}) \n",
    "    print(f'Epoch: {epoch:03d}, Train Acc Nodes: {train_acc_nodes:.4f}, Test Acc Nodes: {test_acc_nodes:.4f}, Train Acc Edges: {train_acc_edges:.4f}, Test Acc Edges: {test_acc_edges:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Saving the following model:*\n",
    "- Performance: Epoch: 001, Train Acc Nodes: 0.9832, Test Acc Nodes: 0.9824, Train Acc Edges: 0.9687, Test Acc Edges: 0.9685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParityGameNetwork(\n",
      "  (core): GAT(3, 256, num_layers=10)\n",
      "  (node_classifier): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "    (4): Softmax(dim=1)\n",
      "  )\n",
      "  (edge_classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "    (4): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'GAT_pg_solver_20220914.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unparsing predicted strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[142, 3], edge_index=[2, 5176], y_nodes=[142], y_edges=[5176], batch=[142], ptr=[2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(test_loader)\n",
    "game = next(it)\n",
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parity 142;\n",
      "0 1 2;\n",
      "1 1 60;\n",
      "2 1 2;\n",
      "3 1 19;\n",
      "4 0 15;\n",
      "5 0 12;\n",
      "6 0 50;\n",
      "7 0 7;\n",
      "8 0 8;\n",
      "9 1 22;\n",
      "10 1 22;\n",
      "11 0 7;\n",
      "12 0 26;\n",
      "13 1 9;\n",
      "14 1 19;\n",
      "15 0 15;\n",
      "16 0 18;\n",
      "17 0 7;\n",
      "18 0 7;\n",
      "19 1 2;\n",
      "20 0 17;\n",
      "21 0 4;\n",
      "22 1 19;\n",
      "23 1 22;\n",
      "24 1 2;\n",
      "25 1 9;\n",
      "26 0 26;\n",
      "27 1 28;\n",
      "28 1 2;\n",
      "29 1 71;\n",
      "30 1 2;\n",
      "31 1 28;\n",
      "32 1 2;\n",
      "33 0 8;\n",
      "34 0 26;\n",
      "35 0 8;\n",
      "36 0 48;\n",
      "37 1 0;\n",
      "38 0 7;\n",
      "39 1 28;\n",
      "40 0 8;\n",
      "41 1 0;\n",
      "42 1 24;\n",
      "43 1 29;\n",
      "44 0 7;\n",
      "45 1 3;\n",
      "46 0 8;\n",
      "47 1 23;\n",
      "48 0 8;\n",
      "49 1 2;\n",
      "50 0 35;\n",
      "51 0 11;\n",
      "52 1 52;\n",
      "53 1 24;\n",
      "54 0 8;\n",
      "55 0 8;\n",
      "56 0 7;\n",
      "57 1 57;\n",
      "58 0 7;\n",
      "59 0 7;\n",
      "60 1 2;\n",
      "61 0 61;\n",
      "62 0 62;\n",
      "63 1 63;\n",
      "64 1 37;\n",
      "65 1 13;\n",
      "66 1 0;\n",
      "67 1 23;\n",
      "68 0 7;\n",
      "69 0 15;\n",
      "70 0 38;\n",
      "71 1 71;\n",
      "72 1 2;\n",
      "73 0 7;\n",
      "74 1 3;\n",
      "75 0 7;\n",
      "76 0 8;\n",
      "77 1 2;\n",
      "78 1 78;\n",
      "79 1 79;\n",
      "80 1 53;\n",
      "81 0 11;\n",
      "82 1 52;\n",
      "83 1 0;\n",
      "84 1 0;\n",
      "85 0 11;\n",
      "86 1 86;\n",
      "87 0 7;\n",
      "88 0 4;\n",
      "89 0 7;\n",
      "90 1 0;\n",
      "91 1 28;\n",
      "92 1 0;\n",
      "93 0 50;\n",
      "94 0 7;\n",
      "95 1 0;\n",
      "96 1 0;\n",
      "97 0 8;\n",
      "98 1 2;\n",
      "99 0 38;\n",
      "100 1 0;\n",
      "101 0 15;\n",
      "102 0 11;\n",
      "103 1 2;\n",
      "104 0 104;\n",
      "105 1 3;\n",
      "106 0 70;\n",
      "107 0 107;\n",
      "108 0 8;\n",
      "109 1 2;\n",
      "110 0 17;\n",
      "111 1 111;\n",
      "112 1 31;\n",
      "113 0 4;\n",
      "114 1 2;\n",
      "115 1 32;\n",
      "116 0 12;\n",
      "117 0 15;\n",
      "118 0 11;\n",
      "119 1 119;\n",
      "120 0 7;\n",
      "121 0 16;\n",
      "122 1 24;\n",
      "123 0 7;\n",
      "124 0 21;\n",
      "125 0 8;\n",
      "126 1 1;\n",
      "127 0 11;\n",
      "128 1 3;\n",
      "129 0 8;\n",
      "130 0 15;\n",
      "131 0 131;\n",
      "132 0 8;\n",
      "133 1 133;\n",
      "134 0 7;\n",
      "135 0 15;\n",
      "136 1 2;\n",
      "137 1 19;\n",
      "138 1 14;\n",
      "139 1 60;\n",
      "140 1 0;\n",
      "141 0 16;\n"
     ]
    }
   ],
   "source": [
    "it = iter(test_loader)\n",
    "game = next(it)\n",
    "\n",
    "def get_index_of_winning_edge(tensor):\n",
    "    max_weight = None\n",
    "    for i in range(len(tensor)):\n",
    "        if tensor[i].item() == 1:\n",
    "            return i\n",
    "        \n",
    "    return 0\n",
    "\n",
    "print(f\"parity {len(game.x)};\")\n",
    "\n",
    "winning_edge_index = [None] * len(game.x)\n",
    "\n",
    "for edge_index in range(len(game.y_edges)):\n",
    "    start_node = game.edge_index[0][edge_index]\n",
    "    current_winning_edge_index = winning_edge_index[start_node]\n",
    "    \n",
    "    if current_winning_edge_index == None:\n",
    "        winning_edge_index[start_node] = edge_index\n",
    "        continue\n",
    "    \n",
    "    if game.y_edges[edge_index].item() > game.y_edges[current_winning_edge_index].item():\n",
    "        winning_edge_index[start_node] = edge_index\n",
    "        \n",
    "for start_node in range(len(winning_edge_index)):\n",
    "    owner = 0 if game.x[start_node][1].item() else 1\n",
    "    next_node = game.edge_index[1][winning_edge_index[start_node]]\n",
    "    print(f\"{start_node} {owner} {next_node};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model application example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(test_loader)\n",
    "next(it)\n",
    "example_game = next(it)\n",
    "out_nodes, out_edges = model(example_game.x, example_game.edge_index) \n",
    "pred_nodes = out_nodes.argmax(dim=1)\n",
    "pred_edges = out_edges.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output 1: Winning reagions of players 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted regions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual winning regions (Calculated by pgsolver)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_game.y_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output 2: Winning strategies\n",
    "\n",
    "A **1** means that the edge belongs to a winning strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted winning strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,  ..., 664, 665, 666],\n",
       "        [ 40,   1,  26,  ..., 613, 605, 613]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_game.edge_index[:,example_game.y_edges == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Winning strategy from pgsolver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9,   9,  20, 101, 117, 117, 138, 138, 138, 138, 292, 292, 292],\n",
       "        [ 12,  16,  16, 150,  51, 102,  71, 125, 153, 178, 250, 309, 334]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_game.edge_index[:,pred_edges == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17852"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_game.y_edges.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
